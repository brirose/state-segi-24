---
title: "Create Complete Severity Layers"
author: "Shive Lab (B. Baker)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(sf)
library(terra)
library(janitor)

```

*CBI severity (1984 to 2017): R5 Basal Area %, 4 class severity
  -in NAD_1983_Albers

*Grove boundaries
  -NAD83 / UTM zone 11N

*Calfire perimeters
  -NAD83 / California Albers
  -find fires missing from R5 assessment
  -bind those that we have, check that they fill full perimeters
  
*Outputs: 2 fire severity layers
  -classified BA severity: 1984 to 2023
  -RdNbr for fires with high severity, include year ranges
  
  

```{r}

#check layers in gdb
#st_layers(here("data/spatial_data/inputs/fire/fire22_1.gdb"))

#input assessments we have , initially from GDB, now made to a shapefile
# cbi2017 <- st_read(here("data/spatial_data/inputs/fire/VegBurnSeverity18_1.gdb"), layer = "VegBurnSeverity_BestAssessment")%>% clean_names()

cbi2017 <- st_read(here("data/spatial_data/outputs/cbi_2017/cbi_2017.shp"))


# perimeters <- st_read("data/spatial_data/inputs/fire/fire22_1.gdb", layer = "firep22_1") %>% 
#   clean_names() %>% 
#   st_transform(crs(cbi2017)) %>%  #make consistent crs
#   st_cast("MULTIPOLYGON")
# 
groves <- st_read(here("data/spatial_data/inputs/forest/2023_GS_Groves_OTI_public.gdb"), layer = "OGS_Groves_2023_97_public") %>%
  clean_names() %>%
  st_transform(crs(cbi2017)) %>% #uniform crs
  st_cast("MULTIPOLYGON") #convert multisurface to multipolygon


```

```{r}
#reduce size of full severity layer by masking to include only aprox range of SEGI

# range_segi <- st_read(here("data/spatial_data/inputs/forest/groves_extent.shp")) %>% 
#   st_transform(crs(cbi2017)) %>% 
#   rename("range" = "Id") %>% 
#   mutate(range = "yes")
# 
# cbi_2017_full <- cbi2017 %>% 
#   mutate(assess_type = case_when(
#     assess_type == "a" ~ "immediate",
#     T ~ "extended"),
#   id = str_trunc(vb_id, 12, ellipsis = "")) %>% 
#   select(id, burnsev, assess_type, fire_year)
# 
# cbi_2017_range <- st_join(cbi_2017_full, range_segi) %>% 
#   filter(range == "yes")
# 
# dir.create(here("data/spatial_data/outputs/cbi_2017"))
# st_write(cbi_2017_range, here("data/spatial_data/outputs/cbi_2017/cbi_2017.shp"), append = F)


```



```{r}
#derived inputs

#fire pereimeters within groves
perimeters_segi <- st_read(here("data/spatial_data/outputs/perimeters_segi/perimeters_segi.shp"))

#BA that we did not yet have, is missing a little window of Windy Fire, layer made in combine_gee
ba_additional <- st_read(here("data/spatial_data/outputs/ba_missing/ba_missing.shp")) %>% 
  st_transform(crs(cbi2017))

#rdnbr for fires that intersect with groves AND that have high severity, also missing window of Windy Fire, but is cat 1 & 2 so will not be used
rdnbr_segi_rast <- rast(here("data/spatial_data/outputs/needFires_rdnbr/needFires_rdnbr.tif"))


#CBI that we did not yet have, is missing a little window of Windy Fire, layer made in combine_gee
cbi_missing <- st_read(here("data/spatial_data/outputs/CBI_missing/CBI_missing.shp")) %>% 
  st_transform(crs(cbi2017))

```


```{r}
#fix where derived inputs are missing windy fire severity

#windy mask polygon
windy <- st_read(here("data/spatial_data/inputs/fire/windy_mask/ca3604711863120210910_20210611_20220614_burn_bndy.shp")) %>% 
  st_transform(crs(cbi2017))

#rdnbr from MTBI
rdnbr_windy <- rast(here("data/spatial_data/inputs/fire/mtbs_windy_rdnbr.tif"))%>% 
  project(crs(cbi2017)) %>% 
  mask(windy)

category_rangesCBI <- c("0 <= CBI < 0.1", "0.1 <= CBI < 1.25", "1.25 <= CBI < 2.25", "2.25 <= CBI <= 3.0")

category_namesCBI <- c("Undetected change", "Low severity", "Moderate severity", "High severity")

breaks4CBI <- tibble(
  CBI_from = c(0, 0.1, 1.25, 2.25), #lefthand breaks CBI
  CBI_to = c(0.1, 1.25, 2.25, 3), #righthand breaks in CBI
  rdnbr_from = -369 + 421.7 * exp(sqrt(CBI_from*0.389)), #converted to rdnbr
  rdnbr_to = -369 + 421.7 * exp(sqrt(CBI_to*0.389)), #converted to rdnbr
  becomes =  c(1, 2, 3, 4)) %>% #name of categories
  select(!contains("CBI")) #removes unneeded columns
  
breaks4CBI[1,1] = minmax(rdnbr_windy)[1] #make lowest category include minimum in raster
breaks4CBI[4,2] = minmax(rdnbr_windy)[2] #and highest be max in raster


cbi_windy_missing <- mask(rdnbr_windy, cbi_missing, inverse = T, touches = F) %>% 
  classify(breaks4CBI,
           right = F, # include "from" value in category
           include.lowest = T) %>% #include max value
  as.factor() #make factor

x <- levels(cbi_windy_missing)[[1]] %>% #pull levels of raster
  rename(ba_category = Layer_1) # rename level

x$class <- category_namesCBI #add categories as a level
x$class <- category_rangesCBI #add categories as a level

levels(cbi_windy_missing) <- x #save new levels back

#writeRaster(cbi_windy_missing, here("data/spatial_data/outputs/debug_windy_missing.tif"))


cbi_windy_missing <- cbi_windy_missing %>% 
  as.polygons() %>% 
  st_as_sf()

#is still making a few little holes
#st_write(cbi_windy_missing, here("data/spatial_data/outputs/debug_windy_missing.shp"), append = F)

#CBI for Coffee Pot Fire, raster from ravg
cbi_coffee <- rast(here("data/spatial_data/inputs/fire/2024_CA_CoffeePot_RAVG/ca3639211876520240803_20240729_20240914_rdnbr_cbi4.tif"))%>% 
  project(crs(cbi2017))


#writeRaster(cbi_windy_missing, here("data/spatial_data/outputs/debug_windy_missing.tif"))

cbi_coffee <- cbi_coffee %>% 
  #clamp(lower = 1, upper = 4, values = F) %>% #remove erroneous values
  as.polygons() %>% 
  st_as_sf() %>% 
  rename("burnsev" = "ca3639211876520240803_20240729_20240914_rdnbr_cbi4") %>% 
  mutate(
    name = "2024coffeepot",
    assss_t = "ravg",
    year = "2024",
    id = "2024COFFEE"
  ) %>% 
  filter(!burnsev == 0)

#st_write(cbi_coffee, here("data/spatial_data/outputs/debug_coffee_missing.shp"), append = F)
  
cbi_windy_missing <- cbi_windy_missing %>%   
    mutate(
    name = "2021windy",
    assss_t = "mtbi",
    year = "2021",
    id = "2021WINDY"
  )


cbi_additional <- bind_rows(cbi_missing, cbi_windy_missing, cbi_coffee) %>% 
  st_cast("POLYGON") %>% 
  summarise(.by = c ("id","name","assss_t", "year","burnsev"), across(geometry, st_union))

#st_write(cbi_additional, here("data/spatial_data/outputs/debug_poly.shp"), append = F)

```

```{r}

cbi_all <- st_read(here("data/spatial_data/outputs/cbi_all/cbi_all.shp"))
  
#same same for REDWOOD 2023

rdnbr_redwood <- rast(here("data/spatial_data/inputs/fire/fires_needed/2023_REDWOOD_rdnbr.tif"))%>% 
  project(crs(cbi_all))


breaks4CBI[1,1] = minmax(rdnbr_redwood)[1] #make lowest category include minimum in raster
breaks4CBI[4,2] = minmax(rdnbr_redwood)[2] #and highest be max in raster


cbi_redwood <- rdnbr_redwood %>% 
  classify(breaks4CBI,
           right = F, # include "from" value in category
           include.lowest = T) %>% #include max value
  as.factor() #make factor

x <- levels(cbi_redwood)[[1]] %>% #pull levels of raster
  rename(ba_category = "2023_REDWOOD_rdnbr") # rename level

x$class <- category_namesCBI #add categories as a level
x$class <- category_rangesCBI #add categories as a level

levels(cbi_redwood) <- x #save new levels back

cbi_redwood <- cbi_redwood %>% 
as.polygons() %>% 
  st_as_sf() %>% 
  rename("burnsev" = "ba_category") %>% 
  mutate(
    burnsev = as.numeric(burnsev),
    name = "2024redwood",
    assss_t = "ravg",
    year = "2024",
    id = "2024REDWOOD"
  ) %>% 
  filter(!burnsev == 0)


cbi_all_022425 <- bind_rows(cbi_all, cbi_redwood)

st_write(cbi_all_022425, here("data/spatial_data/outputs/cbi_all_24feb25/cbi_all_24feb25.shp"))

```




```{r}
#select only perimeters where they intersect with groves

groves <- groves %>% 
  select(grove_name, land_steward_list)

perimeters <- perimeters %>% 
  select(year, fire_name, inc_num) %>% 
  filter(year >= 1984) %>% 
  mutate(
    fire_name = case_when(is.na(fire_name) ~ inc_num, T ~ fire_name), #replace na fire names
    fire_name = str_replace(fire_name," ","_"),
    vb_id = paste(year,fire_name, sep = ""), #create ID found in severity data
    id = str_trunc(vb_id, 12, ellipsis = "")
    )

#create layer that is all fire area in sequoia groves since 1984
perimeters_segi <- st_intersection(groves, perimeters)

#calculate polygon area
perimeters_segi$area_ha <- as.numeric(st_area(perimeters_segi))*0.0001 

#dir.create(here("data/spatial_data/outputs/perimeters_segi"))
# st_write(perimeters_segi, here("data/spatial_data/outputs/perimeters_segi/perimeters_segi.shp", append = F))

```

```{r}
#select classified fires to 2017 that fall within grove boundaries
#create layer that is classified fire area in sequoia groves 1984-2017
segi_17 <- st_intersection(groves, cbi2017) 

segi_17 <- segi_17 %>% 
  mutate(assss_type = case_when(
    assss_type == "a" ~ "immediate",
    T ~ "extended"
  )) %>% 
  select(vb_id, grove_name, burnsev, assss_type, fire_year) %>% 
  mutate(id = str_trunc(vb_id, 12, ellipsis = ""))

#calc poly area
segi_17$area_ha <- as.numeric(st_area(segi_17))*0.0001 

#dir.create(here("data/spatial_data/outputs/segi_17"))
##st_write(segi_17, here("data/spatial_data/outputs/segi_17/segi_17.shp"), append = F))

```

# Identify data needed

```{r}

firenames <- perimeters_segi %>% 
  st_drop_geometry() %>% 
  select(id, fire_name) %>% 
  unique()

fire_list <- perimeters_segi %>% 
  st_drop_geometry() %>% 
  group_by(id) %>% 
  summarise(area_ha = sum(area_ha)) %>% 
  left_join(firenames)
  
#will not need BA for fires in usfs layer
need_ba <- tibble(id = unique(segi_17$id), need_ba = "N")


#will need rdnbr for fires that have high severity (==4)
need_rdnbr <- segi_17 %>% 
  st_drop_geometry() %>% 
  filter(burnsev == 4) %>% 
  group_by(id) %>% 
  summarise(highsev_area = sum(area_ha)) %>% 
  mutate(need_rdnbr = "Y")


fire_list <- fire_list %>% 
  left_join(need_ba) %>% 
  left_join(need_rdnbr) %>% 
  mutate(
    year = as.numeric(regmatches(id, gregexpr("[[:digit:]]+", id))),
    area_ha = round(area_ha, 1),
    need_ba = case_when(is.na(need_ba) ~ "Y", T ~ need_ba),
    need_rdnbr = case_when(year > 2017 ~ "Y", is.na(need_rdnbr) ~ "N", T ~ need_rdnbr),
    highsev_area = round(case_when(is.na(highsev_area) ~ 0, T ~ highsev_area),2)
  ) %>% 
  filter(!(need_ba == "N" & need_rdnbr == "N"))

fires_needed_list <- unique(fire_list$id)


```

```{r}
#make shapefile with only perimeters that still need info

fires_needed <- perimeters %>% 
  filter(id %in% fires_needed_list) %>% 
  rename(
    Fire_Year = year,
    Fire_ID = id
  ) %>% 
  mutate(
    Start_Day = 152,
    End_Day = 258
  ) %>% 
  filter(inc_num != "00007043") ##in futre could do a spatial check to get rid of this guy

#dir.create(here("data/spatial_data/outputs/fires_needed"))
st_write(fires_needed, here("data/spatial_data/outputs/fires_needed/fires_needed.shp"), append = F)

```


# Combine to make full layers

```{r}
#Complete perimeters (not grove filtered)

#ID which are duplicated
in_new <- unique(cbi_additional$id)
in_old <- unique(cbi2017$id)
in_both <- c(in_new, in_old)
in_both <- in_both[duplicated(in_both)]

#combine together
cbi_all <- cbi_additional %>% 
  filter(!id %in% in_both) %>% 
  bind_rows(cbi2017)


cbi_all <- cbi_all %>%
  mutate(fire_yr = str_extract(id, "\\d{4}")) %>% 
  select(id, fire_yr, burnsev, assss_t, geometry) %>% 
  drop_na()

#check
#plot(ba_segi_all)

#layer is all fires to 2017, relevant fires to present
#dir.create(here("data/spatial_data/outputs/cbi_all"))
st_write(cbi_all, here("data/spatial_data/outputs/cbi_all/cbi_all.shp"), append = F)

```
```{r}
#there are duplicates of fires bc names were different; fixing here without redoing whole layer
cbi_all <- st_read(here("data/spatial_data/outputs/cbi_all/cbi_all.shp"))

fire_byyr <- cbi_all %>% 
  st_drop_geometry() %>% 
  summarize(.by = c(fire_yr, id)) %>% 
  arrange(fire_yr, id)

cbi_fixed <- cbi_all %>% 
filter(!id %in% c("1995CASTLE_W", "2010SHEEP_CO"))

st_write(cbi_fixed, here("data/spatial_data/outputs/cbi_all/cbi_all.shp"), append = F)

```


